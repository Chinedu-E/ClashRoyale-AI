{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from models.autoencoder import VariationalAutoencoder as VAE\n",
    "import utils.config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\anaconda3\\envs\\clashvenv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = VAE((208, 160, 1),\n",
    "            cfg.CONV_FILTERS,\n",
    "            cfg.CONV_KERNEL_SIZES,\n",
    "            cfg.CONV_STRIDES,\n",
    "            cfg.CONV_T_FILTERS,\n",
    "            cfg.CONV_T_KERNEL_SIZES,\n",
    "            cfg.CONV_T_STRIDES,\n",
    "            z_dim=64,\n",
    "            use_batch_norm=True)\n",
    "model.compile(1e-4, 10000)\n",
    "model.model.load_weights(r\"E:\\RL\\Clash Royale\\workspace\\models\\weights\\vae7.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 208, 160, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " encoder_conv_0 (Conv2D)        (None, 104, 80, 32)  544         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 104, 80, 32)  128        ['encoder_conv_0[0][0]']         \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 104, 80, 32)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " encoder_conv_1 (Conv2D)        (None, 52, 40, 64)   32832       ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 52, 40, 64)  256         ['encoder_conv_1[0][0]']         \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 52, 40, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " encoder_conv_2 (Conv2D)        (None, 26, 20, 64)   65600       ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 26, 20, 64)  256         ['encoder_conv_2[0][0]']         \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 26, 20, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " encoder_conv_3 (Conv2D)        (None, 13, 10, 128)  131200      ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 13, 10, 128)  512        ['encoder_conv_3[0][0]']         \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 13, 10, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 16640)        0           ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 64)           1065024     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " log_var (Dense)                (None, 64)           1065024     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 64)           0           ['mu[0][0]',                     \n",
      "                                                                  'log_var[0][0]']                \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 208, 160, 1)  1542657     ['sampling[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,904,033\n",
      "Trainable params: 3,902,945\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 398694 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(r\"E:\\RL\\Clash Royale\\workspace\\card_train\\images_np\",\n",
    "                                         target_size=(208, 160),\n",
    "                                         color_mode= \"grayscale\",\n",
    "                                         class_mode=\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "12460/12460 [==============================] - 19816s 2s/step - batch: 6229.5000 - size: 31.9979 - loss: 45.6402 - vae_r_loss: 35.5405 - vae_kl_loss: 10.0995 - accuracy: 0.2440\n",
      "Epoch 2/3\n",
      "12460/12460 [==============================] - 16565s 1s/step - batch: 6229.5000 - size: 31.9979 - loss: 45.3176 - vae_r_loss: 35.2780 - vae_kl_loss: 10.0391 - accuracy: 0.2440\n",
      "Epoch 3/3\n",
      " 4153/12460 [========>.....................] - ETA: 3:14:59 - batch: 2076.0000 - size: 32.0000 - loss: 45.1827 - vae_r_loss: 35.1215 - vae_kl_loss: 10.0612 - accuracy: 0.2440"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.model.fit(train_data, epochs=3)\n",
    "    model.model.save_weights(r\"E:\\RL\\Clash Royale\\workspace\\models\\weights\\vae7.h5\")\n",
    "except KeyboardInterrupt:\n",
    "    model.model.save_weights(r\"E:\\RL\\Clash Royale\\workspace\\models\\weights\\vae7.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce34a40f40b45a25ff5ed2ae885939dd86bb40d54efbc7491a7643b7f6a9e32d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('clashvenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
